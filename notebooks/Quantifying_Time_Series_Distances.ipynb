{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6QlNOGWGho9PNvwlOcZEq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanks847/EV-Grid-Integration-Study/blob/master/notebooks/Quantifying_Time_Series_Distances.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dtaidistance pyts python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJR0mmKHow1I",
        "outputId": "b8336c65-a5ce-46e7-c041-6b45e06e57f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dtaidistance in /usr/local/lib/python3.10/dist-packages (2.3.10)\n",
            "Requirement already satisfied: pyunicorn in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: pyts in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dtaidistance) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyunicorn) (1.10.1)\n",
            "Requirement already satisfied: python-igraph>=0.7 in /usr/local/lib/python3.10/dist-packages (from pyunicorn) (0.10.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.2.0)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.10/dist-packages (from pyts) (0.56.4)\n",
            "Requirement already satisfied: Levenshtein==0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.21.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.0->python-Levenshtein) (3.1.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.48.0->pyts) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.48.0->pyts) (67.7.2)\n",
            "Requirement already satisfied: igraph==0.10.4 in /usr/local/lib/python3.10/dist-packages (from python-igraph>=0.7->pyunicorn) (0.10.4)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph==0.10.4->python-igraph>=0.7->pyunicorn) (1.6.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.1->pyts) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.signal import coherence\n",
        "from statsmodels.tsa.stattools import acf\n",
        "from pyts.approximation import SymbolicAggregateApproximation\n",
        "from sklearn.utils import resample\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from scipy.signal import correlate\n",
        "from scipy.signal import welch\n",
        "from scipy.stats import f_oneway\n",
        "from scipy.stats import linregress\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from scipy.spatial.distance import euclidean\n",
        "from dtaidistance import dtw\n",
        "from dtaidistance import dtw_visualisation as dtwvis\n",
        "from scipy.stats import entropy\n",
        "from pyts.metrics.dtw import dtw\n",
        "from Levenshtein import distance as lcs_distance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "eDZmDuMT-tDT",
        "outputId": "3a64b4c5-554d-4b7b-c466-0321dcf4a63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-9d435262b0cf>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mLevenshtein\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlcs_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyunicorn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecurrencePlot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyunicorn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msetup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'setup'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N51ZtnbGojif"
      },
      "outputs": [],
      "source": [
        "# DISTANCES\n",
        "def calculate_correlation(X, Y):\n",
        "    correlation = np.corrcoef(X, Y)[0, 1]\n",
        "    return correlation\n",
        "\n",
        "def calculate_cross_correlation(X, Y):\n",
        "    cross_corr = correlate(X, Y, mode='same')\n",
        "    max_corr = np.max(cross_corr)\n",
        "    return max_corr\n",
        "\n",
        "def calculate_euclidean_distance(X, Y):\n",
        "    distance = np.sqrt(np.sum((X - Y)**2))\n",
        "    return distance\n",
        "\n",
        "def calculate_dtw_distance(X, Y):\n",
        "    distance = dtw.distance(X, Y)\n",
        "    return distance\n",
        "\n",
        "def calculate_cosine_similarity(X, Y):\n",
        "    dot_product = np.dot(X, Y)\n",
        "    magnitude_X = np.sqrt(np.sum(X**2))\n",
        "    magnitude_Y = np.sqrt(np.sum(Y**2))\n",
        "    similarity = dot_product / (magnitude_X * magnitude_Y)\n",
        "    return similarity\n",
        "\n",
        "def calculate_mutual_information(X, Y):\n",
        "    return mutual_info_score(X, Y)\n",
        "\n",
        "def calculate_lcs_distance(X, Y):\n",
        "    m, n = len(X), len(Y)\n",
        "    dp = [[0] * (n+1) for _ in range(m+1)]\n",
        "    for i in range(1, m+1):\n",
        "        for j in range(1, n+1):\n",
        "            if X[i-1] == Y[j-1]:\n",
        "                dp[i][j] = dp[i-1][j-1] + 1\n",
        "            else:\n",
        "                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
        "    lcs_distance = m + n - 2 * dp[m][n]\n",
        "    return lcs_distance\n",
        "\n",
        "def calculate_power_spectrum_distance(X, Y):\n",
        "    _, X_power_spectrum = welch(X, nperseg=min(len(X), 256))\n",
        "    _, Y_power_spectrum = welch(Y, nperseg=min(len(Y), 256))\n",
        "    distance = np.sqrt(np.sum((X_power_spectrum - Y_power_spectrum)**2))\n",
        "    return distance\n",
        "\n",
        "def test_variance(X, Y):\n",
        "    statistic, p_value = f_oneway(X, Y)\n",
        "    return p_value\n",
        "\n",
        "def calculate_combined_distance(X, Y, weights):\n",
        "    distances = [\n",
        "        calculate_correlation(X, Y),\n",
        "        calculate_cross_correlation(X, Y),\n",
        "        calculate_euclidean_distance(X, Y),\n",
        "        calculate_dtw_distance(X, Y),\n",
        "        calculate_cosine_similarity(X, Y),\n",
        "        calculate_mutual_information(X, Y),\n",
        "        calculate_lcs_distance(X, Y),\n",
        "        calculate_hurst_exponent(X),\n",
        "        calculate_power_spectrum_distance(X, Y)\n",
        "    ]\n",
        "    combined_distance = np.dot(weights, distances)\n",
        "    return combined_distance\n",
        "\n",
        "def calculate_mutual_info(X, Y):\n",
        "    return mutual_info_score(X, Y)\n",
        "\n",
        "def calculate_entropy(X):\n",
        "    return entropy(X)\n",
        "\n",
        "def calculate_sax_distance(X, Y, n_bins=4):\n",
        "    sax = SymbolicAggregateApproximation(n_bins=n_bins)\n",
        "    X_sax = sax.transform(np.expand_dims(X, axis=0))\n",
        "    Y_sax = sax.transform(np.expand_dims(Y, axis=0))\n",
        "    return dtw(X_sax, Y_sax)\n",
        "\n",
        "def calculate_edit_distance(X, Y, normalized=True):\n",
        "    return lcs_distance(str(X), str(Y)) / max(len(X), len(Y)) if normalized else lcs_distance(str(X), str(Y))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPOTHESIS TESTS\n",
        "def autocorrelation_test(X, Y, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform autocorrelation test on two time series.\n",
        "    \n",
        "    Parameters:\n",
        "        X (array-like): First time series.\n",
        "        Y (array-like): Second time series.\n",
        "        alpha (float, optional): Significance level. Default is 0.05.\n",
        "    \n",
        "    Returns:\n",
        "        str: Test result and interpretation.\n",
        "    \"\"\"\n",
        "    acf_X = acf(X, nlags=len(X))\n",
        "    acf_Y = acf(Y, nlags=len(Y))\n",
        "    _, p_value = stats.ttest_ind(acf_X, acf_Y)\n",
        "    if p_value < alpha:\n",
        "        return \"Reject the null hypothesis. The autocorrelation structures of the two time series are significantly different.\"\n",
        "    else:\n",
        "        return \"Fail to reject the null hypothesis. The autocorrelation structures of the two time series are similar.\"\n",
        "\n",
        "def waveform_distance_test(X, Y, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform waveform distance test on two time series.\n",
        "    \n",
        "    Parameters:\n",
        "        X (array-like): First time series.\n",
        "        Y (array-like): Second time series.\n",
        "        alpha (float, optional): Significance level. Default is 0.05.\n",
        "    \n",
        "    Returns:\n",
        "        str: Test result and interpretation.\n",
        "    \"\"\"\n",
        "    distance_XY = dtw(X, Y)\n",
        "    distance_XX = dtw(X, X)\n",
        "    distance_YY = dtw(Y, Y)\n",
        "    test_statistic = (distance_XY - (distance_XX + distance_YY) / 2) / np.sqrt((distance_XX + distance_YY) / 2)\n",
        "    p_value = stats.norm.sf(np.abs(test_statistic))\n",
        "    if p_value < alpha:\n",
        "        return \"Reject the null hypothesis. The waveform distances of the two time series are significantly different.\"\n",
        "    else:\n",
        "        return \"Fail to reject the null hypothesis. The waveform distances of the two time series are similar.\"\n",
        "\n",
        "def bootstrap_test(X, Y, statistic, n_bootstrap=1000, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform bootstrap test on two time series.\n",
        "    \n",
        "    Parameters:\n",
        "        X (array-like): First time series.\n",
        "        Y (array-like): Second time series.\n",
        "        statistic (function): Function to calculate the test statistic.\n",
        "        n_bootstrap (int, optional): Number of bootstrap iterations. Default is 1000.\n",
        "        alpha (float, optional): Significance level. Default is 0.05.\n",
        "    \n",
        "    Returns:\n",
        "        str: Test result and interpretation.\n",
        "    \"\"\"\n",
        "    np.random.seed(0)\n",
        "    X_bootstrap = resample(X, replace=True, n_samples=len(X))\n",
        "    Y_bootstrap = resample(Y, replace=True, n_samples=len(Y))\n",
        "    test_statistic_X = statistic(X_bootstrap)\n",
        "    test_statistic_Y = statistic(Y_bootstrap)\n",
        "    bootstrap_statistics = []\n",
        "    for _ in range(n_bootstrap):\n",
        "        X_bootstrap = resample(X, replace=True, n_samples=len(X))\n",
        "        Y_bootstrap = resample(Y, replace=True, n_samples=len(Y))\n",
        "        bootstrap_statistics.append(test_statistic(X_bootstrap) - test_statistic(Y_bootstrap))\n",
        "    p_value = np.mean(np.abs(bootstrap_statistics) >= np.abs(test_statistic_X - test_statistic_Y))\n",
        "    if p_value < alpha:\n",
        "        return \"Reject the null hypothesis. The two time series are significantly different based on the bootstrap test.\"\n",
        "    else:\n",
        "        return \"Fail to reject the null hypothesis. The two time series are similar based on the bootstrap test.\"\n",
        "\n",
        "def kolmogorov_smirnov_test(X, Y, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform Kolmogorov-Smirnov test on two time series.\n",
        "    \n",
        "    Parameters:\n",
        "        X (array-like): First time series.\n",
        "        Y (array-like): Second time series.\n",
        "        alpha (float, optional): Significance level. Default is 0.05.\n",
        "    \n",
        "    Returns:\n",
        "        str: Test result and interpretation.\n",
        "    \"\"\"\n",
        "    _, p_value = stats.ks_2samp(X, Y)\n",
        "    if p_value < alpha:\n",
        "        return \"Reject the null hypothesis. The two time series are significantly different based on the Kolmogorov-Smirnov test.\"\n",
        "    else:\n",
        "        return \"Fail to reject the null hypothesis. The two time series are similar based on the Kolmogorov-Smirnov test.\"\n",
        "\n",
        "def spectral_coherence_test(X, Y, fs, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform spectral coherence test on two time series.\n",
        "    \n",
        "    Parameters:\n",
        "        X (array-like): First time series.\n",
        "        Y (array-like): Second time series.\n",
        "        fs (float): Sampling frequency of the time series.\n",
        "        alpha (float, optional): Significance level. Default is 0.05.\n",
        "    \n",
        "    Returns:\n",
        "        str: Test result and interpretation.\n",
        "    \"\"\"\n",
        "    _, coherence_values = coherence(X, Y, fs=fs)\n",
        "    test_statistic = np.mean(coherence_values)\n",
        "    p_value = 1 - stats.chi2.cdf(test_statistic, df=len(coherence_values))\n",
        "    if p_value < alpha:\n",
        "        return \"Reject the null hypothesis. The spectral coherence of the two time series is significantly different.\"\n",
        "    else:\n",
        "        return \"Fail to reject the null hypothesis. The spectral coherence of the two time series is similar.\"\n",
        "\n",
        "def nonlinear_measures_test(X, Y, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform nonlinear measures test on two time series.\n",
        "    \n",
        "    Parameters:\n",
        "        X (array-like): First time series.\n",
        "        Y (array-like): Second time series.\n",
        "        alpha (float, optional): Significance level. Default is 0.05.\n",
        "    \n",
        "    Returns:\n",
        "        str: Test result and interpretation.\n",
        "    \"\"\"\n",
        "    distance_XY = lcss(X, Y)\n",
        "    distance_XX = lcss(X, X)\n",
        "    distance_YY = lcss(Y, Y)\n",
        "    test_statistic = (distance_XY - (distance_XX + distance_YY) / 2) / np.sqrt((distance_XX + distance_YY) / 2)\n",
        "    p_value = stats.norm.sf(np.abs(test_statistic))\n",
        "    if p_value < alpha:\n",
        "        return \"Reject the null hypothesis. The nonlinear measures of the two time series are significantly different.\"\n",
        "    else:\n",
        "        return \"Fail to reject the null hypothesis. The nonlinear measures of the two time series are similar.\"\n",
        "\n",
        "def state_space_modeling_test(X, Y, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform state space modeling test on two time series.\n",
        "    \n",
        "    Parameters:\n",
        "        X (array-like): First time series.\n",
        "        Y (array-like): Second time series.\n",
        "        alpha (float, optional): Significance level. Default is 0.05.\n",
        "    \n",
        "    Returns:\n",
        "        str: Test result and interpretation.\n",
        "    \"\"\"\n",
        "    model_X = SARIMAX(X, order=(1, 0, 0))\n",
        "    model_Y = SARIMAX(Y, order=(1, 0, 0))\n",
        "    results_X = model_X.fit()\n",
        "    results_Y = model_Y.fit()\n",
        "    aic_X = results_X.aic\n",
        "    aic_Y = results_Y.aic\n",
        "    _, p_value = stats.ttest_ind(aic_X, aic_Y)\n",
        "    if p_value < alpha:\n",
        "        return \"Reject the null hypothesis. The state space models of the two time series are significantly different.\"\n",
        "    else:\n",
        "        return \"Fail to reject the null hypothesis. The state space models of the two time series are similar.\"\n"
      ],
      "metadata": {
        "id": "CO8O5acGBQ4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Distance Measurement"
      ],
      "metadata": {
        "id": "LflsrBuoBabF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "Y = np.array([2, 4, 6, 8, 10])\n",
        "weights = np.array([0.2, 0.1, 0.3, 0.2, 0.1, 0.05, 0.05, 0.05, 0.05])\n",
        "\n",
        "# Calculate individual distances\n",
        "correlation = calculate_correlation(X, Y)\n",
        "cross_correlation = calculate_cross_correlation(X, Y)\n",
        "euclidean_distance = calculate_euclidean_distance(X, Y)\n",
        "dtw_distance = calculate_dtw_distance(X, Y)\n",
        "cosine_similarity = calculate_cosine_similarity(X, Y)\n",
        "mutual_information = calculate_mutual_information(X, Y)\n",
        "lcs_distance = calculate_lcs_distance(X, Y)\n",
        "power_spectrum_distance = calculate_power_spectrum_distance(X, Y)\n",
        "\n",
        "# Calculate combined distance\n",
        "combined_distance = calculate_combined_distance(X, Y, weights)\n"
      ],
      "metadata": {
        "id": "9s2_hsmGos7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances= {'Correlation':correlation, \n",
        "              'Corss Correlation':cross_correlation,\n",
        "              'Euclidean Distance':euclidean_distance,\n",
        "              'DTW Distance':dtw_distance,\n",
        "              'Cosine Similarity':cosine_similarity,\n",
        "              'Mutual Information':mutual_information,\n",
        "              'LCS Distance':lcs_distance,\n",
        "              'Hurst Exponent':hurst_exponent,\n",
        "              'PSD Distance':power_spectrum_distance}\n"
      ],
      "metadata": {
        "id": "1cDazupep22H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict(distances, orient='index')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "OiIge4n6smZ4",
        "outputId": "0fd2e6ab-304d-4acc-eee6-7fcf1444514c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             0\n",
              "Correlation           1.000000\n",
              "Corss Correlation   110.000000\n",
              "Euclidean Distance    7.416198\n",
              "DTW Distance          6.082763\n",
              "Cosine Similarity     1.000000\n",
              "Mutual Information    1.609438\n",
              "LCS Distance          6.000000\n",
              "Hurst Exponent      999.000000\n",
              "PSD Distance          8.975587"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c224aec-6ba1-4e7e-bb35-8967e31c8112\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Correlation</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Corss Correlation</th>\n",
              "      <td>110.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Euclidean Distance</th>\n",
              "      <td>7.416198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DTW Distance</th>\n",
              "      <td>6.082763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cosine Similarity</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual Information</th>\n",
              "      <td>1.609438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LCS Distance</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hurst Exponent</th>\n",
              "      <td>999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PSD Distance</th>\n",
              "      <td>8.975587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c224aec-6ba1-4e7e-bb35-8967e31c8112')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c224aec-6ba1-4e7e-bb35-8967e31c8112 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c224aec-6ba1-4e7e-bb35-8967e31c8112');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypotheis Testing"
      ],
      "metadata": {
        "id": "2buRf9SUBcqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([1, 2, 3, 4, 5])\n",
        "Y = np.array([1, 2, 3, 4, 6])\n",
        "\n",
        "print(\"Autocorrelation test:\")\n",
        "print(autocorrelation_test(X, Y))\n",
        "print()\n",
        "\n",
        "print(\"Waveform distance test:\")\n",
        "print(waveform_distance_test(X, Y))\n",
        "print()\n",
        "\n",
        "# Perform other hypothesis tests..."
      ],
      "metadata": {
        "id": "lopEEI4F-jJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentation"
      ],
      "metadata": {
        "id": "gJRX-OQRBqfP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NrVvQzzVFmlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Work\n",
        "\n",
        "I will utilize the following works to improve the anlysis and make the abalysis a bit more verbose.\n",
        "\n",
        "\n",
        "1.   [Bag of recurrence patterns representation for time-series\n",
        "classification](https://hal.science/hal-01774237)\n",
        "\n",
        "2.   [Analyzing Multivariate Dynamics Using Cross-Recurrence Quantification Analysis (CRQA), Diagonal-Cross-Recurrence Profiles (DCRP), and Multidimensional Recurrence Quantification Analysis (MdRQA) â€“ A Tutorial in R](https://doi.org/10.3389/fpsyg.2018.02232)\n",
        "\n",
        "3. [Parametric recurrence quantification analysis of\n",
        "autoregressive processes for pattern recognition in\n",
        "multichannel electroencephalographic data](https://hal.science/hal-02921847)\n",
        "\n",
        "4. [An Empirical Evaluation of Similarity Measures for Time Series Classification](https://arxiv.org/abs/1401.3973)\n",
        "\n",
        "5. [On the Similarity and Dependence of Time Series](https://doi.org/10.3390/math9050550)\n",
        "\n",
        "6. [A Competitive Measure to Assess the Similarity between Two Time Series](https://link.springer.com/chapter/10.1007/978-3-642-32986-9_31)\n",
        "\n",
        "7. [A new similarity index for nonlinear signal analysis based on local\n",
        "extrema patterns](https://doi.org/10.1016/j.physleta.2017.11.022)\n",
        "\n",
        "8. See Reading list in the Notion Project Page \n",
        "\n",
        "\n",
        "I will attempt using the following work to bolster my analysis."
      ],
      "metadata": {
        "id": "Ovi_-bdUDc-6"
      }
    }
  ]
}